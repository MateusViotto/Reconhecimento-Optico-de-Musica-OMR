{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr19b53i3Vbj"
   },
   "source": [
    "# Compondo com inteligência\n",
    "Mateus Augusto Viotto - PC3008967"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Bs2QNYL3Q3J"
   },
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RgaegRY5wUNk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io, transform, util\n",
    "import skimage\n",
    "import cv2\n",
    "import tensorflow.compat.v1 as tf\n",
    "import itertools\n",
    "#from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFcsKQD_MfN7"
   },
   "source": [
    "### Altere para os diretórios correspondentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tNyc7IYaMcHU"
   },
   "outputs": [],
   "source": [
    "diretorio_imagem = 'img2.png'\n",
    "diretorio_vocabulario = 'vocabulary_semantic.txt' #ALTERE PARA O DIRETÓRIO DO VOCABULARIO DISPONÍVEL EM https://github.com/OMR-Research/tf-end-to-end/blob/master/Data/vocabulary_semantic.txt\n",
    "diretorio_modelo = 'model\\semantic_model.meta' #ALTERE PARA O DIRETÓRIO DO MODELO DISPONÍVEL EM https://grfia.dlsi.ua.es/primus/models/PrIMuS/Semantic-Model.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVaMLpZfOIhL"
   },
   "source": [
    "## Funções ler e salvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awBxLx9G3k34"
   },
   "source": [
    "Salva a imagem em formato *jpg* no diretório atual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SByYw4ZsGJCF"
   },
   "outputs": [],
   "source": [
    "def salvar_imagem(imagem, nome):\n",
    "  io.imsave(nome+'.jpg', imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8HFJYVkYljM"
   },
   "source": [
    "Lê o vocabulário armazenado no arquito *txt* e armazena em um dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Fiqtxoodx3l-"
   },
   "outputs": [],
   "source": [
    "def ler_vocabulario(diretorio):\n",
    "  # Abra o arquivo para leitura\n",
    "  with open(diretorio, 'r') as arquivo:\n",
    "      # Leia as linhas e armazene em uma lista\n",
    "      linhas = arquivo.readlines()\n",
    "\n",
    "  # Cada elemento da lista representa uma linha do arquivo\n",
    "\n",
    "  dicionario = dict()\n",
    "  i = 0\n",
    "  for palavra in linhas:\n",
    "\n",
    "      dicionario[i] = palavra.replace(\"\\n\", \"\")\n",
    "      i += 1\n",
    "  return dicionario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyk7-aqO3LZp"
   },
   "source": [
    "## Funções Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Wko6Qfx3uch"
   },
   "source": [
    "Converte uma imagem colorida para escala de cinza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FiBdr7pRErOe"
   },
   "outputs": [],
   "source": [
    "def deixar_cinza(imagem):\n",
    "  return cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21bTJoJv36LK"
   },
   "source": [
    "Binariza a imagem utilizando o método *threshold_sauvola*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GMijztmX0D6e"
   },
   "outputs": [],
   "source": [
    "def binarizar(image):\n",
    "  from skimage.filters import threshold_sauvola\n",
    "\n",
    "  # tamanho da janela de cálculo local do limiar\n",
    "  window_size = 101\n",
    "\n",
    "  # fator de sensibilidade\n",
    "  k = 0.2\n",
    "\n",
    "  # Calcule o limiar de Sauvola\n",
    "  threshold = threshold_sauvola(image, window_size=window_size, k=k)\n",
    "\n",
    "  # Aplique o limiar à imagem para binarizá-la\n",
    "  binary_image = image > threshold\n",
    "\n",
    "  return binary_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INuvxKeT4I7b"
   },
   "source": [
    "Plota um gráfico horizontal da projeção horizontal para visualização da linha de pauta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sKNxQF2l0chP"
   },
   "outputs": [],
   "source": [
    "def linhadepauta(projection_data):\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  # Combina os arrays em um único array\n",
    "  combined_data = [item for sublist in projection_data for item in sublist]\n",
    "\n",
    "  # Define o intervalo de exibição no eixo X\n",
    "  x_values = range(1, len(combined_data) + 1)  # De 1 a N\n",
    "\n",
    "  # Define o passo para os rótulos do eixo X (exibe a cada 300 valores)\n",
    "  x_ticks = list(range(1, len(combined_data) + 1, 50))  # Exibe a cada 300 valores\n",
    "\n",
    "  # Cria um gráfico de barras horizontais\n",
    "  plt.barh(x_values, combined_data, color='black')\n",
    "\n",
    "  # Inverte o eixo Y para que os valores mais altos fiquem no topo\n",
    "  plt.gca().invert_yaxis()\n",
    "\n",
    "  # Configura os rótulos do eixo X\n",
    "  plt.yticks(x_ticks, x_ticks)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cn_73yBX4cUY"
   },
   "source": [
    "Calcula a projeção horizontal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5S4i6tqezdRG"
   },
   "outputs": [],
   "source": [
    "def calcular_projecao(img_data, col_row=1):\n",
    "    # Cria uma máscara onde os valores 0 na imagem original são mapeados para 1, e outros para 0\n",
    "    mask = np.uint8(np.where(img_data == 0, 1, 0))\n",
    "\n",
    "    # Calcula a projeção somando os valores na máscara ao longo de uma coluna (col_row=1) ou linha (col_row=0)\n",
    "    # REDUCE_SUM realiza a soma\n",
    "    # dtype=cv2.CV_32SC1 define o tipo de dados do resultado como 32 bits com sinal\n",
    "    count = cv2.reduce(mask, col_row, cv2.REDUCE_SUM, dtype=cv2.CV_32SC1)\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ux2GOiMf4hFw"
   },
   "source": [
    "Rotaciona a imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BzGq7Y54Donp"
   },
   "outputs": [],
   "source": [
    "def girar_imagem(img_data, angle):\n",
    "\n",
    "  # Rotacionar a imagem\n",
    "  new_image = util.img_as_ubyte(transform.rotate(img_data, angle, mode='wrap'))\n",
    "\n",
    "  return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veiWO21Q4lqa"
   },
   "source": [
    "Endireita a imagem, rotacionando-a caso esteja inclinada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Fq1pn1-wHmke"
   },
   "outputs": [],
   "source": [
    "def alinhar_linhas(img_data):\n",
    "    best_image = None  # Variável para armazenar a melhor imagem alinhada\n",
    "    maximum = 0  # Variável para armazenar o valor máximo de projeção\n",
    "\n",
    "    # Loop através de diferentes ângulos de rotação\n",
    "    for i in range(-40, 40):\n",
    "        angle = 0.25 * i  # Calcula o ângulo de rotação correspondente\n",
    "\n",
    "        # Gira a imagem original pelo ângulo calculado\n",
    "        new_image = girar_imagem(img_data, angle)\n",
    "\n",
    "        # Binariza a nova imagem (converte para imagem binária)\n",
    "        binary_image = binarizar(new_image)\n",
    "\n",
    "        # Calcula a projeção horizontal da imagem binária\n",
    "        horizontal_projection = calcular_projecao(binary_image)\n",
    "\n",
    "        # Encontra o valor máximo na projeção horizontal\n",
    "        max_projection = max(horizontal_projection)\n",
    "\n",
    "        # Verifica se o valor máximo encontrado é maior que o máximo atual\n",
    "        if max_projection > maximum:\n",
    "            best_image = new_image  # Se for maior, atualiza a melhor imagem\n",
    "            maximum = max_projection  # Atualiza o valor máximo\n",
    "\n",
    "    return best_image  # Retorna a melhor imagem alinhada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_lenghts(img_data):\n",
    "    black_runs = {}\n",
    "    white_runs = {}\n",
    "    for i in range(img_data.shape[1]): # for all columns\n",
    "        col = img_data[:,i]\n",
    "        for k, g in itertools.groupby(col):\n",
    "            length = len(list(g))\n",
    "            if k == 0:\n",
    "                black_runs[length] = black_runs.get(length, 0) + 1\n",
    "            else:\n",
    "                white_runs[length] = white_runs.get(length, 0) + 1\n",
    "    line_thickness = max(black_runs, key=black_runs.get)\n",
    "    staff_space = max(white_runs, key=white_runs.get)\n",
    "    return(line_thickness, staff_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esa0XDg_Oor7"
   },
   "source": [
    "## Funções Identificar Símbolos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return (255. - image)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image, height):\n",
    "    width = int(float(height * image.shape[1]) / image.shape[0])\n",
    "    sample_img = cv2.resize(image, (width, height))\n",
    "    return sample_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_tensor_to_strs(sparse_tensor):\n",
    "    indices= sparse_tensor[0][0]\n",
    "    values = sparse_tensor[0][1]\n",
    "    dense_shape = sparse_tensor[0][2]\n",
    "\n",
    "    strs = [ [] for i in range(dense_shape[0]) ]\n",
    "\n",
    "    string = []\n",
    "    ptr = 0\n",
    "    b = 0\n",
    "\n",
    "    for idx in range(len(indices)):\n",
    "        if indices[idx][0] != b:\n",
    "            strs[b] = string\n",
    "            string = []\n",
    "            b = indices[idx][0]\n",
    "\n",
    "        string.append(values[ptr])\n",
    "\n",
    "        ptr = ptr + 1\n",
    "\n",
    "    strs[b] = string\n",
    "\n",
    "    return strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identificar_simbolos(imagem, vocabulario, diretorio):\n",
    "    # Desabilita a execução ansiosa\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    # Cria um novo grafo padrão do TensorFlow\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    # Cria um objeto Saver para importar o modelo\n",
    "    saver = tf.train.import_meta_graph(diretorio)\n",
    "\n",
    "    # Restaura os parâmetros do modelo a partir do arquivo\n",
    "    saver.restore(sess, diretorio[:-5])  # Remove a extensão \".meta\" do diretório\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    # Obter tensores necessários do grafo\n",
    "    input = graph.get_tensor_by_name(\"model_input:0\")  # Dados de entrada\n",
    "    seq_len = graph.get_tensor_by_name(\"seq_lengths:0\")  # Comprimento da sequência\n",
    "    rnn_keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")  # Probabilidade de manter unidades\n",
    "    height_tensor = graph.get_tensor_by_name(\"input_height:0\")  # Altura da entrada\n",
    "    width_reduction_tensor = graph.get_tensor_by_name(\"width_reduction:0\")  # Redução de largura\n",
    "    logits = tf.get_collection(\"logits\")[0]  # Saídas da rede neural (normalmente, saídas da camada softmax)\n",
    "\n",
    "    # Obter constantes do modelo\n",
    "    WIDTH_REDUCTION, HEIGHT = sess.run([width_reduction_tensor, height_tensor])\n",
    "\n",
    "    decoded, _ = tf.nn.ctc_greedy_decoder(logits, seq_len)  # Decodificação CTC\n",
    "\n",
    "    # Pré-processamento da imagem de entrada\n",
    "    image = imagem\n",
    "    image = resize(image, HEIGHT)  # Redimensiona a imagem\n",
    "    image = normalize(image)  # Normaliza a imagem\n",
    "    image = np.asarray(image).reshape(1, image.shape[0], image.shape[1], 1)  # Formata a imagem para o modelo\n",
    "\n",
    "    seq_lengths = [image.shape[2] / WIDTH_REDUCTION]  # Comprimento da sequência\n",
    "\n",
    "    # Executa a rede neural com a imagem de entrada\n",
    "    prediction = sess.run(decoded, feed_dict={\n",
    "        input: image,\n",
    "        seq_len: seq_lengths,\n",
    "        rnn_keep_prob: 1.0,\n",
    "    })\n",
    "\n",
    "    # Converte a saída da decodificação em texto usando o vocabulário\n",
    "    str_predictions = sparse_tensor_to_strs(prediction)\n",
    "\n",
    "    # Retorna a lista de símbolos reconhecidos\n",
    "    return [vocabulario[w] for w in str_predictions[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPBrfGM3NLXb"
   },
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf7MiouZMrIt"
   },
   "source": [
    "### Imagem alinhada e binarizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7G8BdfZ0dsr",
    "outputId": "55cd95fe-a71f-450d-ea4c-57f8497bd309"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_2988\\1301399296.py:2: UserWarning: binarizada.jpg is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(nome+'.jpg', imagem)\n"
     ]
    }
   ],
   "source": [
    "imagem = cv2.imread(diretorio_imagem)\n",
    "imagem_cinza = deixar_cinza(imagem)\n",
    "imagem_binarizada = binarizar(imagem_cinza)\n",
    "\n",
    "salvar_imagem(imagem_binarizada, 'binarizada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vOpfW6cOCM_5"
   },
   "outputs": [],
   "source": [
    "imagem_alinhada = alinhar_linhas(imagem_binarizada)\n",
    "salvar_imagem(imagem_alinhada, 'alinhada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHThcEr1W3Cw"
   },
   "source": [
    "### Linha de pauta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "HOK9n84yIICp",
    "outputId": "7fcae97e-1c63-449b-ba50-94eebc11b801",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "projecao = calcular_projecao(imagem_alinhada)\n",
    "linhadepauta(projecao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JA6qOCZbxU9x"
   },
   "source": [
    "## Identificar símbolos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSRLl4wGISNO",
    "outputId": "bccb7f9e-b22d-4b9a-f771-9b9177add8f4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulario = ler_vocabulario(diretorio_vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "DORRtkyob1zH"
   },
   "outputs": [],
   "source": [
    "# Use a função 'img_as_ubyte' para converter a imagem para ubytes\n",
    "img_data = skimage.img_as_ubyte(imagem_alinhada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_thickness, staff_space = get_reference_lenghts(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1793: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
      "INFO:tensorflow:Restoring parameters from model\\semantic_model\n"
     ]
    }
   ],
   "source": [
    "symbols = identificar_simbolos(img_data, vocabulario, diretorio_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clef-G2', 'timeSignature-C', 'rest-eighth', 'note-C5_eighth', 'note-C5_eighth', 'note-C5_eighth', 'note-C5_eighth', 'note-B4_eighth', 'note-A4_sixteenth', 'note-C5_sixteenth', 'barline', 'note-C5_quarter', 'rest-half', 'barline']\n"
     ]
    }
   ],
   "source": [
    "print(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
